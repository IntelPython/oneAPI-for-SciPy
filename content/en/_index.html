+++
title = "oneAPI for Scientific Python Community"

+++


{{<blocks/lead title="" image_anchor="top" height="min" color="primary">}}
    <div class="row align-items-left mt-3 pt-3">

        <div class="col-lg-12">
            <p class="display-2 mb-0">oneAPI for the Scientific Python Community</p>
            <p></p>

            <p class="display-4 mb-4">
            <a href="https://github.com/diptorupd" style="color: #50aaf4; font-weight: bold;">Diptorup Deb</a> and
            <a href="https://github.com/oleksandr-pavlyk" style="color: #50aaf4; font-weight: bold;">Oleksandr Pavlyk</a>
            </p>

            <div>
            <p class="display-6 mb-0" style="text-align: left">The scientific Python software ecosystem
            for heterogeneous computing is highly fragmented with different set
            of libraries and modules for different architectures. The
            fragmentation of the software ecosystem makes it harder to write
            portable Python code and goes counter to one of the
            <a href="https://peps.python.org/pep-0020/" style="color: lightskyblue">central tenets</a>
            of Python: "Simple is better than complex".
            </p>
            <p></p>

            <p class="display-4 mb-3">No need to reimplement code</p>
            <p class="display-6 mb-0" style="text-align: left">The poster introduces our ongoing work to introduce a programming
            model and set of packages that will help a scientific Python programmer program
            different types of devices such as CPU, GPU, accelerators without
            having to reimplement their code.
            </p>
            <p></p>

            <p class="display-4 mb-3">Use oneAPI directly from Python</p>
            <p class="display-6 mb-0" style="text-align: left">
            The work is based on interfacing
            oneAPI, an open standard for unified device programming, with Python
            and helping a programmer be more productive by efficiently using the
            oneAPI programming model directly from Python.
            </p>
        </div>
        </div>
    </div>
    <div class="col-12 pt-5">
        <div class="pt-1 lead text-center">
            <div class="mx-auto mt-5 mb-5">
                <a class="btn btn-lg btn-secondary mr-3 mb-4" href="{{< relref " /details/programming_model">}}">
                    Programming model <i class="fas fa-arrow-alt-circle-right ml-2"></i>
                </a>
                <a class="btn btn-lg btn-secondary mr-3 mb-4" href="{{< relref " /details/skbuild">}}">
                    Create your oneAPI extension <i class="fas fa-microscope ml-2"></i>
                </a>
                <a class="btn btn-lg btn-secondary mr-3 mb-4" href="{{< relref " /details">}}">
                    Learn more <i class="fas fa-book-reader ml-2"></i>
                </a>
            </div>
        </div>
    </div>
{{</blocks/lead>}}

{{% blocks/lead color="secondary" %}}

## What is oneAPI?

<u>[oneAPI][oneAPI]</u> is an open standard for a unified application
programming interface (API) that delivers a common developer experience across
accelerator architectures, including multi-core CPUs, GPUs, and FPGAs.

<img src="images/oneAPI.svg" width="600" alt="oneAPI unified programming across multiple architectures" />

<p></p>

A freely available implementation of the standard is available through
<u>[Intel<sup>&reg;</sup> oneAPI Toolkits][toolkits]</u>. The <u>[Intell<sup>&reg;</sup> Base Toolkit][basekit]</u> features
an industry-leading C++ compiler that implements <u>[SYCL<sup>*</sup>][sycl]</u>, an evolution of C++
for heterogeneous computing. It also includes a suite of performance libraries, such as
Intel<sup>&reg;</sup> oneAPI Math Kernel Library (<u>[oneMKL][oneMKL]</u>), etc, as well as
<u>[Intel<sup>&reg;</sup> Distribution for Python<sup>*</sup>][idp]</u>.

[oneAPI]: https://www.oneapi.io
[toolkits]: https://www.intel.com/content/www/us/en/developer/tools/oneapi/toolkits.html
[basekit]: https://www.intel.com/content/www/us/en/developer/tools/oneapi/base-toolkit.html
[sycl]: https://www.khronos.org/sycl/
[oneMKL]:
https://www.intel.com/content/www/us/en/develop/documentation/oneapi-programming-guide/top/api-based-programming/intel-oneapi-math-kernel-library-onemkl.html
[idp]: https://www.intel.com/content/www/us/en/developer/tools/oneapi/distribution-for-python.html
[layered-architecture]:
https://www.intel.com/content/www/us/en/developer/articles/technical/expanding-oneapi-support-for-languages-and-accelerators.html
[sycl-five-additions]:
https://www.intel.com/content/www/us/en/developer/articles/technical/five-outstanding-additions-sycl2020.html
[base-training-modules]: https://devcloud.intel.com/oneapi/get_started/baseTrainingModules/
[dpcpp-book]: https://link.springer.com/book/10.1007%2F978-1-4842-5574-2
[julia-oneAPI]: https://github.com/JuliaGPU/oneAPI.jl

{{% /blocks/lead %}}

{{% blocks/lead color="Light" %}}

# Data-parallel extensions for Python

<p style="text-align: left">
The data-parallel extensions for Python are a set of Python packages to help
interface Python with oneAPI and bring the oneAPI programming model to Python
programmers. <a href="{{< relref " /details">}}">Read more ...</a>
</p>

{{< cardpane >}}
  {{< card header=`<p style="font-weight: bold; text-align: center;">dpctl</p>` >}}
  <a href="https://intelpython.github.io/dpctl">dpctl</a> provides Python users access
  to data-parallel computing resources targeted by oneAPI, such as device selection,
  queue construction (used to specify offload target), Unified Shared Memory (USM) allocation,
  and USM-based ND-array object. <a href="https://intelpython.github.io/dpctl/latest/docfiles/dpctl/dpctl.tensor_pyapi.html#dpctl-tensor-pyapi">dpctl.tensor</a>
  submodule lets Python users get their job done using tensor operations powered by pure
  SYCL generic kernels for portability.

  dpctl <a href="{{< relref " /details/skbuild">}}">provides</a> the necessary Python bindings to make a SYCL library into a Python
  native extension and subsequently use it from Python.
  {{< /card >}}
  {{< card header=`<p style="font-weight: bold; text-align: center;">numba-dpex</p>` >}}
  <p class="section-text">
    <a href="https://intelpython.github.io/numba-dpex">numba-dpex</a> is a
    standalone extension to the <a href="https://numba.pydata.org/">Numba</a>
    JIT compiler. Numba-dpex adds two features to Numba:
  </p>
  <p>
    An OpenCL-style compute API to write oneAPI kernels directly in Python.
  </p>
  <p>
    An extension to Numba's parallelizer to generate kernels from
    <a href="https://numba.readthedocs.io/en/stable/user/parallel.html">
    data parallel code regions
    </a> that are identified by Numba and offload them to user specified device.
  </p>
  {{< /card >}}

  {{< card header=`<p style="font-weight: bold; text-align: center;">dpnp</p>` >}}
  <p class="section-text">
    <a href="https://intelpython.github.io/dpnp">dpnp</a> is a NumPy-like
    library that is built using oneAPI DPC++ compiler and oneAPI performance
    libraries such as oneAPI MKL and oneAPI DPC++ Library. dpnp will provide
    cross-architecture performance portability to NumPy users without requiring
    changes to their existing NumPy code.
  </p>
  <p>
    While building on <a
    href="https://intelpython.github.io/dpctl/latest/docfiles/dpctl/dpctl.tensor_pyapi.html#dpctl-tensor-pyapi">dpctl.tensor</a>,
    the <a href="https://intelpython.github.io/dpnp">dpnp</a> extends it with
    richer API surface, as well as with linear algebra, fast Fourier transform,
    and random number generation submodules powered by oneMKL.
  </p>
  {{< /card >}}

{{< /cardpane >}}

{{% /blocks/lead %}}

{{< blocks/section color="secondary" >}}

{{% blocks/feature icon="fab fa-python" title="Install extensions using conda" %}}
<pre style="text-align: left; color: darkslategray; margin-left: 2em;">
$ conda install -c dppy/label/dev dpctl dpnp numba-dpex
</pre>
{{% /blocks/feature %}}


{{% blocks/feature icon="fab fa-github" title="Contributions welcome!" %}}
We do a [Pull Request](https://github.com/IntelPython/dpctl/pulls) contributions workflow on **GitHub** for all projects.
New users are always welcome!
{{% /blocks/feature %}}


{{% blocks/feature icon="fab fa-gitter" title="Feedback" %}}
Find us on [Gitter](https://gitter.im/Data-Parallel-Python/community) <i class="fab fa-gitter"></i>, <br />
create <i class="fab fa-github"></i> issues for [dpctl](https://github.com/IntelPython/dpctl), [numba-dpex](https://github.com/IntelPython/numba-dpex) or [dpnp](https://github.com/IntelPython/dpnp), <br />
get help on [Intel Developer Zone](https://community.intel.com/t5/Intel-Distribution-for-Python/bd-p/distribution-python).
{{% /blocks/feature %}}

{{< /blocks/section>}}
